{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "401e1175",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "48979904",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "\n",
    "import dill\n",
    "import hydra\n",
    "import imageio\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"/home/diffusion_policy\")\n",
    "from diffusion_policy.dataset.base_dataset import BaseImageDataset\n",
    "from diffusion_policy.policy.base_image_policy import BaseImagePolicy\n",
    "from diffusion_policy.workspace.base_workspace import BaseWorkspace\n",
    "\n",
    "precision = 2\n",
    "np.set_printoptions(suppress=True, precision=precision)\n",
    "torch.set_printoptions(precision=precision, sci_mode=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0384f4c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "45bd77fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rundir = \"/home/diffusion_policy/data/outputs/2023.04.09/21.39.45_train_diffusion_unet_hybrid_pick_up_ball\"\n",
    "rundir = \"/home/diffusion_policy/data/outputs/2023.04.10/00.43.12_train_diffusion_unet_hybrid_pick_up_ball/\"\n",
    "ckpt_path = os.path.join(rundir, \"checkpoints\", \"latest.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ebfc4155",
   "metadata": {},
   "outputs": [],
   "source": [
    "payload = torch.load(open(ckpt_path, 'rb'), pickle_module=dill)\n",
    "cfg = payload['cfg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6fa382c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 25\n",
    "cfg[\"dataloader\"][\"batch_size\"] = batch_size\n",
    "cfg[\"dataloader\"][\"pin_memory\"] = False\n",
    "cfg[\"val_dataloader\"][\"batch_size\"] = batch_size\n",
    "cfg[\"val_dataloader\"][\"pin_memory\"] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "804d7f75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============= Initialized Observation Utils with Obs Spec =============\n",
      "\n",
      "using obs modality: low_dim with keys: ['joint_states']\n",
      "using obs modality: rgb with keys: ['images']\n",
      "using obs modality: depth with keys: []\n",
      "using obs modality: scan with keys: []\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/robodiff/lib/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/root/miniconda3/envs/robodiff/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Diffusion params: 6.511707e+07\n",
      "Vision params: 1.119709e+07\n"
     ]
    }
   ],
   "source": [
    "cls = hydra.utils.get_class(cfg._target_)\n",
    "workspace = cls(cfg)\n",
    "workspace: BaseWorkspace\n",
    "workspace.load_payload(payload, exclude_keys=None, include_keys=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "850c1d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "policy: BaseImagePolicy\n",
    "policy = workspace.model\n",
    "if cfg.training.use_ema:\n",
    "    policy = workspace.ema_model\n",
    "\n",
    "device = torch.device('cuda')\n",
    "policy.eval().to(device)\n",
    "\n",
    "# set inference params\n",
    "policy.num_inference_steps = 200 # DDIM inference iterations\n",
    "policy.n_action_steps = policy.horizon - policy.n_obs_steps + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f94e7cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# configure dataset\n",
    "dataset: BaseImageDataset\n",
    "dataset = hydra.utils.instantiate(cfg.task.dataset)\n",
    "assert isinstance(dataset, BaseImageDataset)\n",
    "train_dataloader = DataLoader(dataset, **cfg.dataloader)\n",
    "normalizer = dataset.get_normalizer()\n",
    "\n",
    "# configure validation dataset\n",
    "val_dataset = dataset.get_validation_dataset()\n",
    "val_dataloader = DataLoader(val_dataset, **cfg.val_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8a50326d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "374"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "63e200e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = val_dataloader\n",
    "batch = next(iter(dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac9926ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "policy.num_inference_steps = 100 # DDIM inference iterations\n",
    "n_action_steps = 4\n",
    "batch_idx = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "274a3cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_idx = 5\n",
    "batch[\"obs\"][\"images\"].shape\n",
    "images = batch[\"obs\"][\"images\"][batch_idx].detach().cpu().numpy().transpose(0,2,3,1)\n",
    "images = (images * 255).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e616fa6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "092ba34c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import imageio\n",
    "from IPython.display import Video\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1b306d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_filepath = \"/home/video/output.mp4\"\n",
    "writer = imageio.get_writer(output_filepath, fps=15)\n",
    "for i in range(images.shape[0]):\n",
    "    writer.append_data(images[i])\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "259ea7e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import Video\n",
    "Video.from_file(output_filepath, width=320, height=320)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72d43cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = policy.predict_action(batch[\"obs\"])\n",
    "pred_action = result['action_pred'].detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bc29ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_action[batch_idx, :n_action_steps]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae97e6f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch[\"action\"][batch_idx, :n_action_steps]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a8e20e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "error = pred_action[batch_idx, :n_action_steps] - batch[\"action\"][batch_idx, :n_action_steps].detach().cpu().numpy()\n",
    "error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c2dc05d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69c83c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    dataloader = val_dataloader\n",
    "\n",
    "    pred, gt = [], []\n",
    "\n",
    "    for i, batch in enumerate(dataloader):\n",
    "        result = policy.predict_action(batch[\"obs\"])\n",
    "        pred_action = result['action_pred'].detach().cpu().numpy()\n",
    "        pred.append(pred_action)\n",
    "\n",
    "        gt_action = batch[\"action\"]\n",
    "        gt_action= gt_action.detach().cpu().numpy()\n",
    "        gt.append(gt_action)\n",
    "\n",
    "        if i > 4:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84a97f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = np.concatenate(pred)\n",
    "gt = np.concatenate(gt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e67930a",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_pred_timestep = 8\n",
    "error = np.sqrt((pred[:,:n_pred_timestep] - gt[:, :n_pred_timestep]) ** 2)\n",
    "error.mean(axis=(0,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff4fe904",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred[0, :n_pred_timestep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a97152ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "gt[0, :n_pred_timestep]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9240438b",
   "metadata": {},
   "source": [
    "#\n",
    "train: 0.0072, 0.0047, 0.0066, 0.1946, 0.0163, 0.0182, 0.007\n",
    "val:   0.0223, 0.0155, 0.0212, 0.7429, 0.0603, 0.0578, 0.027 \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74636089",
   "metadata": {},
   "source": [
    "- I'm suspicious of the first euler angle values\n",
    "- the outputs seem to be very inconsistent\n",
    "- are they inconsistent in the training data?\n",
    "- is the normalization doing something weird?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04444b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "policy.normalizer[\"action\"].params_dict[\"offset\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4add413a",
   "metadata": {},
   "outputs": [],
   "source": [
    "policy.normalizer[\"action\"].params_dict[\"scale\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00ac43b6",
   "metadata": {},
   "source": [
    "- ok so the offset is tiny so that's probably fine\n",
    "- but the scale is quite small\n",
    "- which I assume means that it's range is small \n",
    "    - is that the case\n",
    "    - how are the limits computed?\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc07e69c",
   "metadata": {},
   "outputs": [],
   "source": [
    "actions = []\n",
    "for i, batch in enumerate(train_dataloader):\n",
    "    if i > 10:\n",
    "        break\n",
    "    actions.append(batch[\"action\"])\n",
    "actions = torch.cat(actions).reshape(-1, 10)\n",
    "actions = actions.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de23b5d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(actions[:, -1], bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c76b6b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(dataset.replay_buffer[\"actions\"][:,-1], bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18daa75f",
   "metadata": {},
   "outputs": [],
   "source": [
    "actions = np.array(dataset.replay_buffer[\"actions\"]).copy()\n",
    "norm_actions = policy.normalizer[\"action\"].normalize(actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2fbaf62",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(norm_actions[:,-1].detach().cpu().numpy(), bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e2bc471",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "263d543b",
   "metadata": {},
   "source": [
    "- can you convert the policy to torchscript?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0350cc7f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "type Tensor doesn't define __round__ method",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m scripted_policy \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjit\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrace\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpolicy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexample_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck_trace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/robodiff/lib/python3.9/site-packages/torch/jit/_trace.py:750\u001b[0m, in \u001b[0;36mtrace\u001b[0;34m(func, example_inputs, optimize, check_trace, check_inputs, check_tolerance, strict, _force_outplace, _module_class, _compilation_unit)\u001b[0m\n\u001b[1;32m    747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func\n\u001b[1;32m    749\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func, torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mModule):\n\u001b[0;32m--> 750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtrace_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    751\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    752\u001b[0m \u001b[43m        \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mforward\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mexample_inputs\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    753\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    754\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheck_trace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    755\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwrap_check_inputs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcheck_inputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    756\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheck_tolerance\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    757\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstrict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    758\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_force_outplace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    759\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_module_class\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    760\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    762\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    763\u001b[0m     \u001b[38;5;28mhasattr\u001b[39m(func, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__self__\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    764\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__self__\u001b[39m, torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mModule)\n\u001b[1;32m    765\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m func\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mforward\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    766\u001b[0m ):\n\u001b[1;32m    767\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m trace_module(\n\u001b[1;32m    768\u001b[0m         func\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__self__\u001b[39m,\n\u001b[1;32m    769\u001b[0m         {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mforward\u001b[39m\u001b[38;5;124m\"\u001b[39m: example_inputs},\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    776\u001b[0m         _module_class,\n\u001b[1;32m    777\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/robodiff/lib/python3.9/site-packages/torch/jit/_trace.py:967\u001b[0m, in \u001b[0;36mtrace_module\u001b[0;34m(mod, inputs, optimize, check_trace, check_inputs, check_tolerance, strict, _force_outplace, _module_class, _compilation_unit)\u001b[0m\n\u001b[1;32m    963\u001b[0m     argument_names \u001b[38;5;241m=\u001b[39m get_callable_argument_names(func)\n\u001b[1;32m    965\u001b[0m example_inputs \u001b[38;5;241m=\u001b[39m make_tuple(example_inputs)\n\u001b[0;32m--> 967\u001b[0m \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_c\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_method_from_trace\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    968\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    969\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    970\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexample_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    971\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvar_lookup_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    972\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstrict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    973\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_force_outplace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    974\u001b[0m \u001b[43m    \u001b[49m\u001b[43margument_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    975\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    976\u001b[0m check_trace_method \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_c\u001b[38;5;241m.\u001b[39m_get_method(method_name)\n\u001b[1;32m    978\u001b[0m \u001b[38;5;66;03m# Check the trace against new traces created from user-specified inputs\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/robodiff/lib/python3.9/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/robodiff/lib/python3.9/site-packages/torch/nn/modules/module.py:1118\u001b[0m, in \u001b[0;36mModule._slow_forward\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1116\u001b[0m         recording_scopes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m   1117\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1118\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1119\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m   1120\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m recording_scopes:\n",
      "File \u001b[0;32m/home/diffusion_policy/diffusion_policy/policy/diffusion_unet_hybrid_image_policy.py:215\u001b[0m, in \u001b[0;36mDiffusionUnetHybridImagePolicy.forward\u001b[0;34m(self, obs_dict)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, obs_dict: Dict[\u001b[38;5;28mstr\u001b[39m, torch\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Dict[\u001b[38;5;28mstr\u001b[39m, torch\u001b[38;5;241m.\u001b[39mTensor]:\n\u001b[0;32m--> 215\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_action\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobs_dict\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/home/diffusion_policy/diffusion_policy/policy/diffusion_unet_hybrid_image_policy.py:242\u001b[0m, in \u001b[0;36mDiffusionUnetHybridImagePolicy.predict_action\u001b[0;34m(self, obs_dict)\u001b[0m\n\u001b[1;32m    239\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobs_as_global_cond:\n\u001b[1;32m    240\u001b[0m     \u001b[38;5;66;03m# condition through global feature\u001b[39;00m\n\u001b[1;32m    241\u001b[0m     this_nobs \u001b[38;5;241m=\u001b[39m dict_apply(nobs, \u001b[38;5;28;01mlambda\u001b[39;00m x: x[:,:To,\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m]\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m*\u001b[39mx\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m2\u001b[39m:]))\n\u001b[0;32m--> 242\u001b[0m     nobs_features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mobs_encoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mthis_nobs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    243\u001b[0m     \u001b[38;5;66;03m# reshape back to B, Do\u001b[39;00m\n\u001b[1;32m    244\u001b[0m     global_cond \u001b[38;5;241m=\u001b[39m nobs_features\u001b[38;5;241m.\u001b[39mreshape(B, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/robodiff/lib/python3.9/site-packages/torch/nn/modules/module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/robodiff/lib/python3.9/site-packages/torch/nn/modules/module.py:1118\u001b[0m, in \u001b[0;36mModule._slow_forward\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1116\u001b[0m         recording_scopes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m   1117\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1118\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1119\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m   1120\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m recording_scopes:\n",
      "File \u001b[0;32m~/miniconda3/envs/robodiff/lib/python3.9/site-packages/robomimic/models/obs_nets.py:230\u001b[0m, in \u001b[0;36mObservationEncoder.forward\u001b[0;34m(self, obs_dict)\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[38;5;66;03m# maybe process encoder input with randomizer\u001b[39;00m\n\u001b[1;32m    229\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobs_randomizers[k] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 230\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mobs_randomizers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mk\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward_in\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    231\u001b[0m \u001b[38;5;66;03m# maybe process with obs net\u001b[39;00m\n\u001b[1;32m    232\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobs_nets[k] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/home/diffusion_policy/diffusion_policy/model/vision/crop_randomizer.py:99\u001b[0m, in \u001b[0;36mCropRandomizer.forward_in\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tu\u001b[38;5;241m.\u001b[39mjoin_dimensions(out, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     97\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     98\u001b[0m     \u001b[38;5;66;03m# take center crop during eval\u001b[39;00m\n\u001b[0;32m---> 99\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mttf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcenter_crop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    100\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcrop_height\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcrop_width\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    101\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_crops \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    102\u001b[0m         B,C,H,W \u001b[38;5;241m=\u001b[39m out\u001b[38;5;241m.\u001b[39mshape\n",
      "File \u001b[0;32m~/miniconda3/envs/robodiff/lib/python3.9/site-packages/torchvision/transforms/functional.py:545\u001b[0m, in \u001b[0;36mcenter_crop\u001b[0;34m(img, output_size)\u001b[0m\n\u001b[1;32m    542\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m crop_width \u001b[38;5;241m==\u001b[39m image_width \u001b[38;5;129;01mand\u001b[39;00m crop_height \u001b[38;5;241m==\u001b[39m image_height:\n\u001b[1;32m    543\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m img\n\u001b[0;32m--> 545\u001b[0m crop_top \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(\u001b[38;5;28;43mround\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_height\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mcrop_height\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2.0\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    546\u001b[0m crop_left \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(\u001b[38;5;28mround\u001b[39m((image_width \u001b[38;5;241m-\u001b[39m crop_width) \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m2.0\u001b[39m))\n\u001b[1;32m    547\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m crop(img, crop_top, crop_left, crop_height, crop_width)\n",
      "\u001b[0;31mTypeError\u001b[0m: type Tensor doesn't define __round__ method"
     ]
    }
   ],
   "source": [
    "scripted_policy = torch.jit.trace(policy, example_inputs=batch[\"obs\"], check_trace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f174431f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "robodiff",
   "language": "python",
   "name": "robodiff"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
